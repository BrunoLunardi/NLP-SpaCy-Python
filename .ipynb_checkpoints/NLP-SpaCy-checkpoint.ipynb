{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#pip install spacy=2.2.3\n",
    "spacy .__version__\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou AUX\n",
      "aprendendo VERB\n",
      "processamento NOUN\n",
      "de ADP\n",
      "linguagem NOUN\n",
      "natural ADJ\n",
      ", PUNCT\n",
      "curso NOUN\n",
      "em ADP\n",
      "Curitiba PROPN\n"
     ]
    }
   ],
   "source": [
    "#marcação part-of-speech (substantivo, adjetivos, verbos)\n",
    "    #identifica cada entidade das palavras em uma frase\n",
    "\n",
    "#objeto principal para trabalhar com PLN em portugues\n",
    "pln = spacy.load('pt_core_news_sm')\n",
    "\n",
    "#texto para processamento\n",
    "documento = pln('Estou aprendendo processamento de linguagem natural, curso em Curitiba')\n",
    "\n",
    "#CADA PALAVRA DE UMA FRASE É CHAMADA DE TOKEN\n",
    "for token in documento:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou Estou AUX AUX aux Xxxxx True True\n",
      "aprendendo aprender VERB VERB ROOT xxxx True False\n",
      "processamento processamento NOUN NOUN obj xxxx True False\n",
      "de de ADP ADP case xx True True\n",
      "linguagem linguagem NOUN NOUN nmod xxxx True False\n",
      "natural natural ADJ ADJ amod xxxx True False\n",
      ", , PUNCT PUNCT punct , False False\n",
      "curso cursar NOUN NOUN appos xxxx True False\n",
      "em em ADP ADP case xx True True\n",
      "Curitiba Curitiba PROPN PROPN nmod Xxxxx True False\n"
     ]
    }
   ],
   "source": [
    "#legendas dos tokens\n",
    "for token in documento:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "         token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curitiba\n"
     ]
    }
   ],
   "source": [
    "#buscando palavras que são pronomes (PROPN)\n",
    "for token in documento:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou Estou\n",
      "aprendendo aprender\n",
      "processamento processamento\n",
      "de de\n",
      "linguagem linguagem\n",
      "natural natural\n",
      ", ,\n",
      "curso cursar\n",
      "em em\n",
      "Curitiba Curitiba\n"
     ]
    }
   ],
   "source": [
    "#lematização -> palavra com está no dicionário\n",
    "for token in documento:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encontrar', 'encontrar', 'encontrar', 'encontrar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pln('encontrei encontraram encontrarão encontraria')\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aprend'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stematização -> radical da palavra\n",
    "    #desvantagem: palavras diferentes com mesmo radical\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "stemmer.stem('aprendendo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou Estou est\n",
      "aprendendo aprender aprend\n",
      "processamento processamento process\n",
      "de de de\n",
      "linguagem linguagem lingu\n",
      "natural natural natur\n",
      ", , ,\n",
      "curso cursar curs\n",
      "em em em\n",
      "Curitiba Curitiba curitib\n"
     ]
    }
   ],
   "source": [
    "for token in documento:\n",
    "    print(token.text, token.lemma_, stemmer.stem(token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM ORG\n",
      "Estados Unidos LOC\n",
      "Brasil LOC\n",
      "São Paulo LOC\n"
     ]
    }
   ],
   "source": [
    "#reconhecimento entidades nomeadas\n",
    "texto = 'A IBM é uma empresa dos Estados Unidos voltada para a área de informática. Sua sede no Brasil fica em São Paulo e a receita em 2018 foi de aproximadamente 320 bilhões de reais'\n",
    "\n",
    "documento =pln(texto)\n",
    "\n",
    "#imprime todas as entidades que ele localizou no texto informado\n",
    "for entidade in documento.ents:\n",
    "    print(entidade.text, entidade.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Bill Gates nasceu em Seattle em 28/10/1955 e foi o criador da Microsoft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
